---
title: "Usenet Project - CSV Cleaning"
author: "Emerson Johnston"
lastmodifeddate: "2024-08-07"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# Old Read and Merge (DONT RUN)
netmed_threads <- read.csv("CSV Files/Threads/netmed_threads.csv")
netmotss_threads <- read.csv("CSV Files/Threads/netmotss_threads.csv")
netnews_threads <- read.csv("CSV Files/Threads/netnews_threads.csv")
netpolitics_threads <- read.csv("CSV Files/Threads/netpolitics_threads.csv")
netreligion_threads <- read.csv("CSV Files/Threads/netreligion_threads.csv")
netsingles_threads <- read.csv("CSV Files/Threads/netsingles_threads.csv")

netmed_comments <- read.csv("CSV Files/Comments/netmed_comments.csv")
netmotss_comments <- read.csv("CSV Files/Comments/netmotss_comments.csv")
netnews_comments <- read.csv("CSV Files/Comments/netnews_comments.csv")
netpolitics_comments <- read.csv("CSV Files/Comments/netpolitics_comments.csv")
netreligion_comments <- read.csv("CSV Files/Comments/netreligion_comments.csv")
netsingles_comments <- read.csv("CSV Files/Comments/netsingles_comments.csv")

netmed_threads$newsgroup <- "netmed"
netmotss_threads$newsgroup <- "netmotss"
netnews_threads$newsgroup <- "netnews"
netpolitics_threads$newsgroup <- "netpolitics"
netreligion_threads$newsgroup <- "netreligion"
netsingles_threads$newsgroup <- "netsingles"

all_threads <- rbind(netmed_threads, netmotss_threads, netnews_threads, netpolitics_threads, netreligion_threads, netsingles_threads)

netmed_comments$newsgroup <- "netmed"
netmotss_comments$newsgroup <- "netmotss"
netnews_comments$newsgroup <- "netnews"
netpolitics_comments$newsgroup <- "netpolitics"
netreligion_comments$newsgroup <- "netreligion"
netsingles_comments$newsgroup <- "netsingles"

all_comments <- rbind(netmed_comments, netmotss_comments, netnews_comments, netpolitics_comments, netreligion_comments, netsingles_comments)

threads_directory <- "CSV Files/Threads"
comments_directory <- "CSV Files/Comments"

write.csv(all_threads, file.path(threads_directory, "combined_threads.csv"), row.names = FALSE)
write.csv(all_comments, file.path(comments_directory, "combined_comments.csv"), row.names = FALSE)
---

---


# Maintainence

## Reset
```{r}
rm(list = ls()) 
setwd("/Users/emerson/Github/usenet_AIDs_discourses_webpage")
```

## Maintenance
```{r Load LIbraries, Directories, and Datasets}
# Load Libraries
library(tidyverse)
library(readr)
library(webshot)
library(htmltools)
library(ggplot2)
library(dplyr)
library(syuzhet)
library(sjPlot)

# Load Directories
output_directory = "/Users/emerson/Github/usenet_AIDs_discourses_webpage/"
threads_directory <- "/Users/emerson/Github/usenet_AIDs_discourses_webpage/CSV Files/Threads"
comments_directory <- "/Users/emerson/Github/usenet_AIDs_discourses_webpage/CSV Files/Comments"

# Load the datasets
all_threads <- read.csv(file.path(threads_directory, "combined_threads.csv"))
all_comments <- read.csv(file.path(comments_directory, "combined_comments.csv"))
```

```{r Dataset Cleaning}
# Assign unique identifiers to newsgroups
newsgroup_ids <- c("netmed" = "NG01", "netmotss" = "NG02", "netnews" = "NG03",
                   "netpolitics" = "NG04", "netreligion" = "NG05", "netsingles" = "NG06")

# Update the all_threads dataset
all_threads <- all_threads %>%
  # Map newsgroup names to IDs and keep the original newsgroup column
  mutate(newsgroup_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
         # Generate Unique Thread ID
         Unique_ThreadID = paste(newsgroup_ID, ThreadID, sep = "_")) %>%
  # Reorder columns: Unique_ThreadID, newsgroup, newsgroup_ID, followed by the rest
  select(Unique_ThreadID, newsgroup, newsgroup_ID, everything()) %>%
  # Rename ThreadID to NG_Relative_ThreadID
  rename(NG_Relative_ThreadID = ThreadID)

# Update the all_comments dataset
all_comments <- all_comments %>%
  # Map newsgroup names to IDs and keep the original newsgroup column
  mutate(newsgroup_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
         # Generate Unique Comment ID
         Unique_CommentID = paste(newsgroup_ID, Unique.Comment.ID, sep = "_"),
         # Retain old Unique.Comment.ID as NG_Relative_CommentID
         NG_Relative_CommentID = Unique.Comment.ID,
         # Retain old Thread.ID as NG_Relative_ThreadID
         NG_Relative_ThreadID = Thread.ID, 
         # Generate new newsgroup.thread.id
         Thread.ID = paste(newsgroup_ID, Thread.ID, sep = "_"),
         # Retain old Comment.ID as Thread_Relative_CommentID
         Thread_Relative_CommentID = Comment.ID) %>%
  # Reorder columns: Unique_CommentID, newsgroup, newsgroup_ID, followed by the rest
  select(Unique_CommentID, newsgroup, newsgroup_ID, Thread.ID, NG_Relative_CommentID, NG_Relative_ThreadID, Thread_Relative_CommentID, everything()) %>%
  # Drop the old Unique.Comment.ID and Comment.ID columns
  select(-Unique.Comment.ID, -Comment.ID)

# Function to clean the datetime strings
clean_datetime <- function(dt_str) {
  gsub("[^[:alnum:] [:punct:]]", "", dt_str)
}

# Clean the Date.and.Time column
all_comments$Date.and.Time <- sapply(all_comments$Date.and.Time, clean_datetime)

# Convert the cleaned Date.and.Time to POSIXct
all_comments$Date.and.Time <- as.POSIXct(all_comments$Date.and.Time, format = "%b %d, %Y, %I:%M:%S%p")

all_comments$Hour <- as.numeric(format(all_comments$Date.and.Time, "%H"))
all_comments$Date <- as.Date(all_comments$Date.and.Time)

all_threads$Date <- as.Date(all_threads$Date, format = "%m/%d/%y")

# Display the updated dataframes (optional)
head(all_threads)
head(all_comments)
```

```{r Run and Add Sentiment Scores} 
all_comments <- all_comments %>% mutate(SentimentScore = get_sentiment(Full.Text, method = "afinn"))
```

```{r Save Cleaned CSVs to File}
write.csv(all_threads, file.path(threads_directory, "combined_threads_cleaned.csv"), row.names = FALSE)
write.csv(all_comments, file.path(comments_directory, "combined_comments_cleaned.csv"), row.names = FALSE)
```

# Additional Filtering
```{r Filter by Keyword}
# List of extended keywords and phrases
keywords <- c("aids", "hiv", "acquired immune deficiency syndrome", "human immunodeficiency virus",
              "gay plague", "gay cancer", "kaposi's sarcoma", "pneumocystis pneumonia",
              "homosexual disease", "gay disease", "gay fear", "fear of gay", "fear of homosexual",
              "sexual orientation disease")

# Function to flag comments with keywords
flag_keywords <- function(text) {
  # Convert text to lowercase
  text <- tolower(text)
  # Check if any keyword is present
  grepl(paste(keywords, collapse = "|"), text)
}

# Add a column to indicate if the comment contains any keyword
all_comments <- all_comments %>%
  mutate(Contains_Keyword = flag_keywords(Full.Text))

# Identify threads with at least one comment containing a keyword
threads_with_keywords <- all_comments %>%
  filter(Contains_Keyword) %>%
  distinct(Thread.ID) %>%
  pull(Thread.ID)

# Filter comments in threads with at least one keyword
comments_in_keyword_threads <- all_comments %>%
  filter(Thread.ID %in% threads_with_keywords)

# Group by newsgroup and calculate required statistics
keywords_summary_df <- comments_in_keyword_threads %>%
  group_by(newsgroup) %>%
  summarize(
    Comments_with_Keywords = sum(Contains_Keyword),
    Conversations_Mentioned_In = n_distinct(Thread.ID),
    Total_Comments_In_Threads = n(),
    Percent_Total_Comments_w_Keyword = (Comments_with_Keywords / Total_Comments_In_Threads) * 100
  )

# Add a totals row
totals <- keywords_summary_df %>%
  summarize(
    newsgroup = "Total",
    Comments_with_Keywords = sum(Comments_with_Keywords),
    Conversations_Mentioned_In = sum(Conversations_Mentioned_In),
    Total_Comments_In_Threads = sum(Total_Comments_In_Threads),
    Percent_Total_Comments_w_Keyword = (Comments_with_Keywords / Total_Comments_In_Threads) * 100
  )

# Combine the summary with the totals row
keywords_summary_df <- bind_rows(keywords_summary_df, totals)

# Print the keyword summary data frame with totals
print(keywords_summary_df)
```

```{r Save Keyword CSVs to File}
# Collect all related threads and comments
related_threads <- all_threads %>%
  filter(Unique_ThreadID %in% threads_with_keywords) %>%
  filter(Date <= as.Date("1988-12-31")) 

related_comments <- all_comments %>%
  filter(Thread.ID %in% threads_with_keywords) %>%
  filter(Date <= as.Date("1988-12-31")) 

# Write the related threads and comments to CSV files
write.csv(related_threads, file.path(threads_directory, "aids_related_threads.csv"), row.names = FALSE)
write.csv(related_comments, file.path(comments_directory, "aids_related_comments.csv"), row.names = FALSE)
```

# Table and Figures
```{r Descriptive Statistics}
# Calculate statistics using dplyr
summary_df <- all_comments %>%
  group_by(newsgroup) %>%
  summarize(
    Threads = n_distinct(Thread.ID),
    Comments = n(),
    Authors = n_distinct(Author),
    Avg_Comments_Per_Thread = Comments / Threads,
    Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
  )

# Add a totals row
totals <- summary_df %>%
  summarize(
    newsgroup = "Total",
    Threads = sum(Threads),
    Comments = sum(Comments),
    Authors = n_distinct(all_comments$Author),
    Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
    Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
  )

# Combine the summary with the totals row
summary_df <- bind_rows(summary_df, totals)

# Print the summary data frame with totals
tab_df(summary_df, file = paste0(output_directory, "Images and Tables/descriptive_statistics_table.html"))
```
